{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобор признаков (**Feature Selection**) может понадобится, когда:\n",
    "- Мы нагенерировали много фичей и нужно уменьшить их количество\n",
    "- Есть ковариации в предикторах\n",
    "- Некоторые фичи не обладают никакой предсказательной способностью и в модели они не нужны\n",
    "\n",
    "Почему плохо когда слишком много предикторов:\n",
    "- Долго обучаются модели\n",
    "- Строк мало => появляется переобучение\n",
    "- Модели становятся менее интерпертируемыми\n",
    "\n",
    "-----\n",
    "\n",
    "Значимость признаков (**Feature Importance**) - ранжирование признаков по вкладу в качество модели. \n",
    "Рассчитанные вклады признаков могут понадобиться:\n",
    "- для понимания структуры модели\n",
    "- как основа для последующего Feature Selection.\n",
    "\n",
    "Под \"качеством\" признака понимается любая мера ассоциации признака с целевой переменной (например, корреляция,  коэффициент регрессии или что-либо ещё), либо вклад признака в качество модели.\n",
    "\n",
    "-----\n",
    "\n",
    "Есть несколько стандартных стратегий для отбора признаков:\n",
    "1. Univariate Feature Selection\n",
    "       когда отдельно по каждому признаку рассчитывается его \"качество\" и отбираются наиболее сильные признаки\n",
    "2. Recursive Feature Elimination\n",
    "       когда ищем оптимальную комбинацию признаков\n",
    "3. Feature Importance Selection\n",
    "       когда качество считается по каждому признаку, но не отдельно, а в результате обучения модели на всех признаках\n",
    "\n",
    "RFE в отличие от UFS учитывает возможные зависимости между признаками!\n",
    "\n",
    "-----\n",
    "\n",
    "Далее рассмотрим подробнее каждый подход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VarianceThreshold\n",
    "\n",
    "Для начала можем удалить все фичи, которые являются констатами или очень мало изменяются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   attr1  attr2  attr3  attr4\n",
      "0      0      2      0      3\n",
      "1      0      1      4      3\n",
      "2      0      1      1      3\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "data = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\n",
    "X = pandas.DataFrame(data, columns=['attr1','attr2','attr3','attr4'])\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменяемость признака меряется его дисперсией (variance):\n",
    "$$s_N = \\sqrt {\\frac{1}{N}\\sum\\limits_{i = 1}^N {\\left( {x_i - \\bar x} \\right)^2 } }$$\n",
    "\n",
    "Если дисперсия близка к нулю, признак вероятно бесполезен.\n",
    "\n",
    "Параметр **threshold** задает минимально допустимое значение дисперсии признака.\n",
    "Условие threshold = 0 соответствует детектированию констант."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для расчета дисперсий можем использовать метод fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(attr0)=0.0\n",
      "Var(attr1)=0.2222222222222222\n",
      "Var(attr2)=2.888888888888889\n",
      "Var(attr3)=0.0\n"
     ]
    }
   ],
   "source": [
    "selector.fit(X)\n",
    "for feature_num, feature in enumerate(selector.variances_):\n",
    "    print(\"Var(attr{})={}\".format(feature_num,feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы отфильтровать предикторы, применяем transform():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [1 4]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "X_filtered = selector.transform(X)\n",
    "print(X_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Feature Selection \n",
    "\n",
    "UFS - собирательтное название подходов, при которых для каждого признака считается некая мера его ассоциации с целевой переменной, а затем признаки сортируются по убыванию этой меры и фильтруются.\n",
    "\n",
    "**Какие могут быть меры ассоциации:**\n",
    "- Тест Хи-квадрат\n",
    "- F-тест для регрессии\n",
    "- F-тест для ANOVA\n",
    "- Mutual Information\n",
    "- AUC ROC\n",
    "- Корреляция Пирсона\n",
    "- $R^2$\n",
    "- Любые другие\n",
    "\n",
    "Помимо самого значения теста (score) всегда учитываться ещё и достоверность ассоциации в виде соотвествующей p-value (вероятности ошибки I рода). Как правило, предельно допустимую p-value ставят равной 0.01-0.05 и этот параметр называется alpha.\n",
    "\n",
    "**Какие есть способы отбора:**\n",
    "- SelectKBest \n",
    "        выбираем k лучших признаков\n",
    "- Select Percentiles \n",
    "        выбираем top-n % лучших признаков\n",
    "- SelectFpr\n",
    "        выбираем признаки со статистически значимой зависимостью (False Positive Rate)\n",
    "- SelectFdr \n",
    "        выбираем признаки со статистически значимой зависимостью (False Discovery Rate)\n",
    "- SelectFwe\n",
    "        выбираем признаки признаки со статистически значимой зависимостью с помощью Family-wise Error Rate\n",
    "- SelectFromModel\n",
    "        выбираем признаки, которые некоторый внешний классификатор отметил как важные\n",
    "\n",
    "**Чуть подробнее о FPR, FDR и FWE**\n",
    "\n",
    "Задача - выбрать значимые признаки. Если на самом деле признак незначим, имеет место ложное срабатывание.\n",
    "Поскольку признаков несколько, есть разные стратегии отобора.\n",
    "- Family-wise: выбираем признаки так, чтобы вероятноть ложного срабатывания по каждому признаку была меньше заданного порога alpha\n",
    "- FPR: выбираем набор признаков, у которого вероятность ложного срабатывания меньше alpha (то есть есть хотя один ложное срабатывание)\n",
    "- FDR: процедура, допускающая определенную долю ложных срабатываний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее по различным мерам ассоциации\n",
    "\n",
    "**Мера Хи-квадрат**\n",
    "\n",
    "Определяет меру зависимости между категориальным признаком и категориальной целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|categorical|categorical|\n",
    "\n",
    "Идея: если никакой зависимости между ними нет, то в рамках каждой категории признака целевая переменная должна быть  распределена одинаково. \n",
    "\n",
    "Тест Хи-квадрат численно измеряет наличие неравномерностей в таком распределении.\n",
    "\n",
    "Как работает $\\chi^2$?\n",
    "\n",
    "Рассмотрим Contingency Table (таблицу сопряженности). По строкам - признак (во что играют на вечеринке), по столбцам целевая перемнная (что едят во время игры).\n",
    "\n",
    "<img src=\"img/contingency_table.png\" width=500>\n",
    "\n",
    "Если y никак не зависит от X, то мы ожидаем в каждой ячейке увидеть такое количество наблюдений:\n",
    "\n",
    "$$E_{ij} = \\frac{row\\_total \\cdot column\\_total}{global\\_total}$$\n",
    "\n",
    "Посчитаем, насколько ожидание отличается от реальности:\n",
    "\n",
    "$$\\tilde{\\chi}^2=\\frac{1}{d}\\sum_{i} \\sum_{j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\$$\n",
    "\n",
    "где:\n",
    "- $O_{ij}$ (observed) - наблюдаемое количество кейсов в ячейке (i,j), \n",
    "\n",
    "- $E_{ij}$ (expected) - ожидаемое количество кейсов в ячейке (i,j)\n",
    "\n",
    "\n",
    "Теперь нужно проверить значимость полученного различия (ведь оно могло получиться большим случайно). \n",
    "\n",
    "Для этого анализируем распределение $\\chi^2$: выбираем допустимую вероятность ошибки alpha и сравниваем с ней p-value нашего теста. Считаем, что различие значимо, если наблюдаемый p-value для распределения Хи-квадрат меньше порогового.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F-test для регрессии**\n",
    "\n",
    "Определяет меру зависимости между числовым признаком и числовой целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|numeric|numeric|\n",
    "\n",
    "Мы строим регрессию отдельно на каждом признаке (Target ~ Feature) и проверяем нулевой ли коэффициент у этой регрессии. Нулевой коэффициент говорит о том, что зависимости нет.\n",
    "\n",
    "В регрессионном анализе классический тест для определения нулевого коэффициента - это <a href=\"https://en.wikipedia.org/w/index.php?title=Lack-of-fit_sum_of_squares#The_test_statistic\">F-тест</a> Фишера.\n",
    "\n",
    "Как считается F-тест:\n",
    "1. SSM = $\\sum{(\\hat{y}-\\bar{y})^2}$ - сумма квадратов отклонений регресии от среднего значения\n",
    "\n",
    "\n",
    "2. SSE = $\\sum{\\epsilon} = \\sum{(\\hat{y}-y)^2}$ - сумма квадратов ошибок регрессии\n",
    "\n",
    "    Хотим проверить: Если магнитуда отклонений регрессии примерно равна магнитуде ошибок, значит вся вариация данных объясняется только случайными ошибками и целевая переменная не зависит от признака.\n",
    "\n",
    "\n",
    "3. Нормируем каждую сумму числом степеней свободы и считаем F-статистику\n",
    "\n",
    "\n",
    "$$F = \\frac{SSM / (p-1)}{SSE / (n - p)}$$\n",
    "\n",
    "    Рассчитанная статистика имеет распределние Фишера. Распределение Фишера выглядит примерно так:\n",
    "\n",
    "   <img src=\"img/f.gif\">\n",
    "\n",
    "4. Задаем alpha - допустимую веротяность ошибки I рода (ложного срабатывания). Как правило, это 5% или 1%.\n",
    "\n",
    "    То есть не чаще чем 1 раз за 20 экспериментов, тест будет показывать зависимость, когда её на самом деле нет.\n",
    "\n",
    "\n",
    "5. Определяем p-value для нашего теста. Если оно больше максимально допустимого, то целевая переменная не зависит от признака. \n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F-test для классификации**\n",
    "\n",
    "Определяет меру зависимости между числовым признаком и категориальной целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|numeric|categorical|\n",
    "\n",
    "\n",
    "Если зависимости нет, средние значение признака по каждому классу должны быть одинаковыми\n",
    "\n",
    "Для проверки равенства средних значений используется F-статистика\n",
    "\n",
    "Математически:\n",
    "$$F = \\frac{MS_b}{MS_w}$$\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutual Information**\n",
    "\n",
    "Mutual Information - статистическая мера зависимости между двумя случайными величинами\n",
    "\n",
    "Определяет меру зависимости между любым признаком и любой целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|any|any|\n",
    "\n",
    "Идея: если зависимости нет, условное распределение одной переменной P(y|x) не должно зависеть от распределения второй переменной, то есть P(y|x) должна быть равна P(y).\n",
    "\n",
    "В отличие от корреляции, которая детектирует только линейную зависимость, MI ловит любые зависимости.\n",
    "\n",
    "Математически:\n",
    "\n",
    "$$I(X,Y) = \\sum_y \\sum_x P(x,y) \\log{\\frac{P(x,y)}{P(x)P(y)}}$$\n",
    "\n",
    "Видим, что $\\frac{P(x,y)}{P(x) \\cdot P(y)} = \\frac{P(y | x)}{P(y)}$, то есть просто показатель, как сильно значение X меняет распределение целевой переменной y.\n",
    "\n",
    "Затем эти штуки суммируются по всем значениям x и y, с учетом популярности этих значений P(x,y) и получаем меру взаимной информации I(x,y).\n",
    "\n",
    "Легко видеть, что если X и Y независимы (и P(x,y)=P(x)P(y)), то MI = 0\n",
    "\n",
    "На практике формулами посчитать не можем, поэтому считается итерационным алгоритмом Mutual Information\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUC ROC**\n",
    "\n",
    "\n",
    "Определяет меру зависимости между числовым признаком и бинарной целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|numeric|binary|\n",
    "\n",
    "\n",
    "Считаем ROC AUC как обычно, но в качестве скорингового бала используем значения признака. Если зависимости между признаком и целевой переменной нету, ROC AUC = 0.5. Если признак можно использовать для полного разделения двух классов, то ROC AUC = 1.0.\n",
    "\n",
    "Как считается ROC AUC?\n",
    "\n",
    "Простейший классификатор - взять признак  и определить его пороговое значение - все, что выше относим к классу \"1\", все что ниже, относим к классу \"0\".\n",
    "\n",
    "У такого классификатора считаем Recall (долю верно классифицируемого класса \"1\") и Specificity (долю верно классифицируемого класса \"0\") и отмечаем точку на ROC-плоскости.\n",
    "<img src=\"img/roc1.png\" width=400>\n",
    "\n",
    "Меняя порог от 0.0 до 1.0, получаем множество классификаторов и, как следствие, непрерывную ROC-кривую\n",
    "\n",
    "<img src=\"img/roc2.png\" width=300>\n",
    "\n",
    "Площадь под этой кривой ROC AUC - мера разделимости двух классов данной моделью.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Корреляция Пирсона**\n",
    "\n",
    "Определяет меру зависимости между числовым признаком и числовой целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|numeric|numeric|\n",
    "\n",
    "Классическая мера, известная всем.\n",
    "$$Corr(X,Y) = \\frac{E[(X-\\bar{X})(Y-\\bar{Y})]}{E[(X-\\bar{X})^2]E[(Y-\\bar{Y})^2]}$$\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Статистика $R^2$**\n",
    "\n",
    "Определяет меру зависимости между числовым признаком и бинарной целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|numeric|numeric|\n",
    "\n",
    "Можно обратить внимание, что почти полностью повторяет описанный выше F-тест Фишера для регрессии.\n",
    "\n",
    "$$R^2 = \\frac{SSM}{SSE}$$\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала рассчитаем F-статистику для числовых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature0: F-test score=233.84, p-value=2.8904783526016577e-32\n",
      "\n",
      "Feature1: F-test score=32.94, p-value=5.201563255171195e-08\n",
      "\n",
      "Feature2: F-test score=1341.94, p-value=4.2018731529488986e-76\n",
      "\n",
      "Feature3: F-test score=1592.82, p-value=4.1553110153134456e-81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "df = load_iris()\n",
    "X, y = df['data'], df['target']\n",
    "\n",
    "from sklearn.feature_selection import f_regression\n",
    "scores, pvalues = f_regression(X,y)\n",
    "\n",
    "for num, (s,p) in enumerate(zip(scores,pvalues)):\n",
    "    print(\"Feature{}: F-test score={}, p-value={}\\n\".format(num,round(s,2),p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут все атрибуты значимы. Попробуем другой датасет, он поменьше => p-value будут больше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature0: F-test score=3.22, p-value=0.08942226312017666\n",
      "\n",
      "Feature1: F-test score=5.78, p-value=0.027167887465660654\n",
      "\n",
      "Feature2: F-test score=0.97, p-value=0.337364665679547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_linnerud\n",
    "df = load_linnerud()\n",
    "X, y = df['data'], df['target'][:,0]\n",
    "scores, pvalues = f_regression(X, y)\n",
    "\n",
    "for num, (s,p) in enumerate(zip(scores,pvalues)):\n",
    "    print(\"Feature{}: F-test score={}, p-value={}\\n\".format(num,round(s,2),p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим селектор на базе данной статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFpr(alpha=0.05, score_func=<function f_regression at 0x1a1afe7048>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFdr, SelectFpr, SelectFwe\n",
    "feature_selector = SelectFpr(score_func=f_regression, alpha=0.05)\n",
    "feature_selector.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем, что он насчитал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08942226 0.02716789 0.33736467]\n",
      "[3.22293987 5.78220199 0.97152578]\n"
     ]
    }
   ],
   "source": [
    "print(feature_selector.pvalues_)\n",
    "print(feature_selector.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew = feature_selector.fit_transform(X,y)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что селектор отфильтровал два признака со слишком большими p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем отфильтровать признаки с помощью chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "df = load_wine()\n",
    "X,y = df['data'], df['target']\n",
    "\n",
    "import pandas\n",
    "pandas.DataFrame(X, columns = df['feature_names']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 5)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "feature_selector = SelectKBest(score_func=chi2, k=5)\n",
    "feature_selector.fit(X,y)\n",
    "Xnew = feature_selector.transform(X)\n",
    "\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какие признаки оставил селектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     alcalinity_of_ash\n",
       "4             magnesium\n",
       "6            flavanoids\n",
       "9       color_intensity\n",
       "12              proline\n",
       "dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = pandas.Series(df['feature_names'])\n",
    "feature_names[feature_selector.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "\n",
    "RFE - поиск оптимального набора предикторов путем последовательного удаления \"плохих\" фичей из перовначального набора. \n",
    "\n",
    "Для оценки качества фичей используется любой классификатор, который возвращает списком величину вклада предкитора в качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Sklearn за это отвечает класс RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные параметры класса RFE:\n",
    "- estimator - классификатор\n",
    "- n_features_to_select - какое число признаков нужно в итоге отобрать\n",
    "- step - сколько признаков убирать из набора на каждом шаге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svc = SVR(kernel=\"linear\")\n",
    "rfecv = RFECV(estimator=svc, n_features_to_select = 10, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для определения требуемого кол-ва фичей можно воспользоваться удобным методом RFECV.\n",
    "\n",
    "Метод делает то же самое, что GridSearchCV, но сетка параметров и содержит различные кол-ва признаков [1,2 ... k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные параметры:\n",
    "- estimator - классификатор\n",
    "- cv - параметры кросс-валидации\n",
    "- scoring - метрика для оценки качества признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2), scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем построить график точности классифкатора в зависимости от числа признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Optimal number of features : 3\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=25, n_informative=3,\n",
    "                           n_redundant=2, n_repeated=0, n_classes=8,\n",
    "                           n_clusters_per_class=1, random_state=0)\n",
    "\n",
    "svc = SVC(kernel=\"linear\")\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2), scoring='accuracy')\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какие признаки мы в итоге отобрали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можем проследить, в каком порядке убирались признаки. Индекс 1 соотвествует отобранным в итоге признакам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  1, 12, 19, 15,  6, 17,  1,  2, 21, 23, 11, 16, 10, 13, 22,  8,\n",
       "       14,  1, 20,  7,  9,  3,  4, 18])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многие алгоритмы (в том числе RanfomForest и XGBoost) в процессе обучения модели также рассчитывают Feature Importance по всем предикторам. Эти feature importances также можно использовать для отбора признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Sklearn за это отвечает метод SelectFromModel\n",
    "\n",
    "**Что для этого нужно?**\n",
    "\n",
    "Классификатор должен возвращать либо атрибут coef_, либо атрибут feature_importance_\n",
    "\n",
    "Какие есть классификаторы, удовлетворяющие этому требованию:\n",
    "\n",
    "- ансамбли деревьев\n",
    "    - RandomForestClassifier\n",
    "    - ExtraTreesClassifier\n",
    "    \n",
    "- линейные модели с коэффициентами\n",
    "    - LogisticREgression\n",
    "    - LinearRegression\n",
    "\n",
    "- модели с L1-регуляризацией\n",
    "    - LinearSVC\n",
    "    - Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1-регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зануление некоторых коэффициентов - часть процесса L1-регуляризации в линейных моделях. Следовательно его можно использовать для отбора признаков.\n",
    "\n",
    "Чем больше мы поставили коэффициент регуляризации, тем больше коэффициентов зануляется, и тем меньше ненулевых признаков в модели.\n",
    "\n",
    "Опция prefit=True означает, что модель уже обучена и ещё раз ее запускать не нужно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Load some data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Lets make classifer\n",
    "from sklearn.svm import LinearSVC\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "\n",
    "model = SelectFromModel(estimator = lsvc, prefit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяя метод transform() мы отфильтровываем часть плохих признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew = model.transform(X)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес считает важность признаков в процессе обучения.\n",
    "\n",
    "Случайный лес состоит из большого количества решающих деревьев. Все деревья разные, так как при построении дерева признак для очередного разбиения выбирается в определнной степени случайно.\n",
    "\n",
    "Важность признака в RandomForest определяется через то, как часто признак участвует в разбиениях. Чем чаще он используется и чем ближе находится разбиение к корню, тем важнее признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Konstantin/anaconda/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Load some data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Lets make classifer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что алгоритм насчитал в качестве важности признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature0 importance = 0.0732\n",
      "Feature1 importance = 0.02227\n",
      "Feature2 importance = 0.38004\n",
      "Feature3 importance = 0.52449\n"
     ]
    }
   ],
   "source": [
    "for colnum, colname in enumerate(iris['feature_names']):\n",
    "    print(\"Feature{} importance = {}\".format(colnum, round(rf.feature_importances_[colnum],5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию SelectFromModel выбирает все, что выше медианы (то есть половину признаков)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew = model.transform(X)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Порог можно поставить и вручную параметром threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SelectFromModel(estimator = rf, prefit=True, threshold = 0.1)\n",
    "Xnew = model.transform(X)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё его удобно определять визуально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Отсортируем по убыванию значиомсти\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Посчитаем стандартное отклонение (ошибку) значимости\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ошибка большая из-за того, что датасет маленький"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем например всё, что выше 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_transformer = SelectFromModel(estimator = rf, threshold = 0.25, prefit=True)\n",
    "Xnew = select_transformer.transform(X)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
