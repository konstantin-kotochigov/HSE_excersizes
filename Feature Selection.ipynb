{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобор признаков (**Feature Selection**) может понадобится, когда:\n",
    "- Мы нагенерировали много фичей и нужно уменьшить их количество\n",
    "- Есть ковариации в предикторах\n",
    "- Некоторые фичи не обладают никакой предсказательной способностью и в модели они не нужны\n",
    "\n",
    "Почему плохо когда слишком много предикторов:\n",
    "- Долго обучаются модели\n",
    "- Строк мало => появляется переобучение\n",
    "- Модели становятся менее интерпертируемыми\n",
    "\n",
    "-----\n",
    "\n",
    "Значимость признаков (**Feature Importance**) - ранжирование признаков по вкладу в качество модели. \n",
    "Рассчитанные вклады признаков могут понадобиться:\n",
    "- для понимания структуры модели\n",
    "- как основа для последующего Feature Selection.\n",
    "\n",
    "Под \"качеством\" признака понимается любая мера ассоциации признака с целевой переменной (например, корреляция,  коэффициент регрессии или что-либо ещё), либо вклад признака в качество модели.\n",
    "\n",
    "-----\n",
    "\n",
    "Есть несколько стандартных стратегий для отбора признаков:\n",
    "1. Univariate Feature Selection\n",
    "       когда отдельно по каждому признаку рассчитывается его \"качество\" и отбираются наиболее сильные признаки\n",
    "2. Recursive Feature Elimination\n",
    "       когда ищем оптимальную комбинацию признаков\n",
    "3. Feature Importance Selection\n",
    "       когда качество считается по каждому признаку, но не отдельно, а в результате обучения модели на всех признаках\n",
    "\n",
    "RFE в отличие от UFS учитывает возможные зависимости между признаками!\n",
    "\n",
    "-----\n",
    "\n",
    "Далее рассмотрим подробнее каждый подход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VarianceThreshold\n",
    "\n",
    "Для начала можем удалить все фичи, которые являются констатами или очень мало изменяются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "data = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\n",
    "X = pandas.DataFrame(data, columns=['attr1','attr2','attr3','attr4'])\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменяемость признака меряется его дисперсией (variance):\n",
    "$$s_N = \\sqrt {\\frac{1}{N}\\sum\\limits_{i = 1}^N {\\left( {x_i - \\bar x} \\right)^2 } }$$\n",
    "\n",
    "Если дисперсия близка к нулю, признак вероятно бесполезен.\n",
    "\n",
    "Параметр **threshold** задает минимально допустимое значение дисперсии признака.\n",
    "Условие threshold = 0 соответствует детектированию констант."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для расчета дисперсий можем использовать метод fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.fit(X)\n",
    "for feature_num, feature in enumerate(selector.variances_):\n",
    "    print(\"Var(attr{})={}\".format(feature_num,feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы отфильтровать предикторы, применяем transform():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = selector.transform(X)\n",
    "print(X_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Feature Selection \n",
    "\n",
    "UFS - собирательтное название подходов, при которых для каждого признака считается некая мера его ассоциации с целевой переменной, а затем признаки сортируются по убыванию этой меры и фильтруются.\n",
    "\n",
    "**Какие могут быть меры ассоциации:**\n",
    "- Тест Хи-квадрат\n",
    "- F-тест для регрессии\n",
    "- F-тест для ANOVA\n",
    "- Mutual Information\n",
    "- AUC ROC\n",
    "- Корреляция Пирсона\n",
    "- $R^2$\n",
    "- Любые другие\n",
    "\n",
    "Помимо самого значения теста (score) всегда учитываться ещё и достоверность ассоциации в виде соотвествующей p-value (вероятности ошибки I рода). Как правило, предельно допустимую p-value ставят равной 0.01-0.05 и этот параметр называется alpha.\n",
    "\n",
    "**Какие есть способы отбора:**\n",
    "- SelectKBest \n",
    "        выбираем k лучших признаков\n",
    "- Select Percentiles \n",
    "        выбираем top-n % лучших признаков\n",
    "- SelectFpr\n",
    "        выбираем признаки со статистически значимой зависимостью (False Positive Rate)\n",
    "- SelectFdr \n",
    "        выбираем признаки со статистически значимой зависимостью (False Discovery Rate)\n",
    "- SelectFwe\n",
    "        выбираем признаки признаки со статистически значимой зависимостью с помощью Family-wise Error Rate\n",
    "- SelectFromModel\n",
    "        выбираем признаки, которые некоторый внешний классификатор отметил как важные\n",
    "\n",
    "**Чуть подробнее о FPR, FDR и FWE**\n",
    "\n",
    "Задача - выбрать значимые признаки. Если на самом деле признак незначим, имеет место ложное срабатывание.\n",
    "Поскольку признаков несколько, есть разные стратегии отобора.\n",
    "- Family-wise: выбираем признаки так, чтобы вероятноть ложного срабатывания по каждому признаку была меньше заданного порога alpha\n",
    "- FPR: выбираем набор признаков, у которого вероятность ложного срабатывания меньше alpha (то есть есть хотя один ложное срабатывание)\n",
    "- FDR: процедура, допускающая определенную долю ложных срабатываний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее по различным мерам ассоциации\n",
    "\n",
    "**Мера Хи-квадрат**\n",
    "\n",
    "Определяет меру зависимости между категориальным признаком и категориальной целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|categorical|categorical|\n",
    "\n",
    "Идея: если никакой зависимости между ними нет, то в рамках каждой категории признака целевая переменная должна быть  распределена одинаково. \n",
    "\n",
    "Тест Хи-квадрат численно измеряет наличие неравномерностей в таком распределении.\n",
    "\n",
    "Как работает $\\chi^2$?\n",
    "\n",
    "Рассмотрим Contingency Table (таблицу сопряженности). По строкам - признак (во что играют на вечеринке), по столбцам целевая перемнная (что едят во время игры).\n",
    "\n",
    "<img src=\"img/contingency_table.png\" width=500>\n",
    "\n",
    "Если y никак не зависит от X, то мы ожидаем в каждой ячейке увидеть такое количество наблюдений:\n",
    "\n",
    "$$E_{ij} = \\frac{row\\_total \\cdot column\\_total}{global\\_total}$$\n",
    "\n",
    "Посчитаем, насколько ожидание отличается от реальности:\n",
    "\n",
    "$$\\tilde{\\chi}^2=\\frac{1}{d}\\sum_{i} \\sum_{j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\$$\n",
    "\n",
    "где:\n",
    "- $O_{ij}$ (observed) - наблюдаемое количество кейсов в ячейке (i,j), \n",
    "\n",
    "- $E_{ij}$ (expected) - ожидаемое количество кейсов в ячейке (i,j)\n",
    "\n",
    "\n",
    "Теперь нужно проверить значимость полученного различия (ведь оно могло получиться большим случайно). \n",
    "\n",
    "Для этого анализируем распределение $\\chi^2$: выбираем допустимую вероятность ошибки alpha и сравниваем с ней p-value нашего теста. Считаем, что различие значимо, если наблюдаемый p-value для распределения Хи-квадрат меньше порогового.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F-test для регрессии**\n",
    "\n",
    "Определяет меру зависимости между числовым признаком и числовой целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|numeric|numeric|\n",
    "\n",
    "Мы строим регрессию отдельно на каждом признаке (Target ~ Feature) и проверяем нулевой ли коэффициент у этой регрессии. Нулевой коэффициент говорит о том, что зависимости нет.\n",
    "\n",
    "В регрессионном анализе классический тест для определения нулевого коэффициента - это <a href=\"https://en.wikipedia.org/w/index.php?title=Lack-of-fit_sum_of_squares#The_test_statistic\">F-тест</a> Фишера.\n",
    "\n",
    "Как считается F-тест:\n",
    "1. SSM = $\\sum{(\\hat{y}-\\bar{y})^2}$ - сумма квадратов отклонений регресии от среднего значения\n",
    "\n",
    "\n",
    "2. SSE = $\\sum{\\epsilon} = \\sum{(\\hat{y}-y)^2}$ - сумма квадратов ошибок регрессии\n",
    "\n",
    "    Хотим проверить: Если магнитуда отклонений регрессии примерно равна магнитуде ошибок, значит вся вариация данных объясняется только случайными ошибками и целевая переменная не зависит от признака.\n",
    "\n",
    "\n",
    "3. Нормируем каждую сумму числом степеней свободы и считаем F-статистику\n",
    "\n",
    "\n",
    "$$F = \\frac{SSM / (p-1)}{SSE / (n - p)}$$\n",
    "\n",
    "    Рассчитанная статистика имеет распределние Фишера. Распределение Фишера выглядит примерно так:\n",
    "\n",
    "   <img src=\"img/f.gif\">\n",
    "\n",
    "4. Задаем alpha - допустимую веротяность ошибки I рода (ложного срабатывания). Как правило, это 5% или 1%.\n",
    "\n",
    "    То есть не чаще чем 1 раз за 20 экспериментов, тест будет показывать зависимость, когда её на самом деле нет.\n",
    "\n",
    "\n",
    "5. Определяем p-value для нашего теста. Если оно больше максимально допустимого, то целевая переменная не зависит от признака. \n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F-test для классификации**\n",
    "\n",
    "Определяет меру зависимости между числовым признаком и категориальной целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|numeric|categorical|\n",
    "\n",
    "\n",
    "Если зависимости нет, средние значение признака по каждому классу должны быть одинаковыми\n",
    "\n",
    "Для проверки равенства средних значений используется F-статистика\n",
    "\n",
    "Математически:\n",
    "$$F = \\frac{MS_b}{MS_w}$$\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutual Information**\n",
    "\n",
    "Mutual Information - статистическая мера зависимости между двумя случайными величинами\n",
    "\n",
    "Определяет меру зависимости между любым признаком и любой целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|any|any|\n",
    "\n",
    "Идея: если зависимости нет, условное распределение одной переменной P(y|x) не должно зависеть от распределения второй переменной, то есть P(y|x) должна быть равна P(y).\n",
    "\n",
    "В отличие от корреляции, которая детектирует только линейную зависимость, MI ловит любые зависимости.\n",
    "\n",
    "Математически:\n",
    "\n",
    "$$I(X,Y) = \\sum_y \\sum_x P(x,y) \\log{\\frac{P(x,y)}{P(x)P(y)}}$$\n",
    "\n",
    "Видим, что $\\frac{P(x,y)}{P(x) \\cdot P(y)} = \\frac{P(y | x)}{P(y)}$, то есть просто показатель, как сильно значение X меняет распределение целевой переменной y.\n",
    "\n",
    "Затем эти штуки суммируются по всем значениям x и y, с учетом популярности этих значений P(x,y) и получаем меру взаимной информации I(x,y).\n",
    "\n",
    "Легко видеть, что если X и Y независимы (и P(x,y)=P(x)P(y)), то MI = 0\n",
    "\n",
    "На практике формулами посчитать не можем, поэтому считается итерационным алгоритмом Mutual Information\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUC ROC**\n",
    "\n",
    "\n",
    "Определяет меру зависимости между числовым признаком и бинарной целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|numeric|binary|\n",
    "\n",
    "\n",
    "Считаем ROC AUC как обычно, но в качестве скорингового бала используем значения признака. Если зависимости между признаком и целевой переменной нету, ROC AUC = 0.5. Если признак можно использовать для полного разделения двух классов, то ROC AUC = 1.0.\n",
    "\n",
    "Как считается ROC AUC?\n",
    "\n",
    "Простейший классификатор - взять признак  и определить его пороговое значение - все, что выше относим к классу \"1\", все что ниже, относим к классу \"0\".\n",
    "\n",
    "У такого классификатора считаем Recall (долю верно классифицируемого класса \"1\") и Specificity (долю верно классифицируемого класса \"0\") и отмечаем точку на ROC-плоскости.\n",
    "<img src=\"img/roc1.png\" width=400>\n",
    "\n",
    "Меняя порог от 0.0 до 1.0, получаем множество классификаторов и, как следствие, непрерывную ROC-кривую\n",
    "\n",
    "<img src=\"img/roc2.png\" width=300>\n",
    "\n",
    "Площадь под этой кривой ROC AUC - мера разделимости двух классов данной моделью.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Корреляция Пирсона**\n",
    "\n",
    "Определяет меру зависимости между числовым признаком и числовой целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|numeric|numeric|\n",
    "\n",
    "Классическая мера, известная всем.\n",
    "$$Corr(X,Y) = \\frac{E[(X-\\bar{X})(Y-\\bar{Y})]}{\\sigma(X)\\sigma(Y)}$$\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Статистика $R^2$**\n",
    "\n",
    "Определяет меру зависимости между числовым признаком и бинарной целевой переменной\n",
    "\n",
    "|Feature|Target|\n",
    "|---|---|\n",
    "|numeric|numeric|\n",
    "\n",
    "Можно обратить внимание, что почти полностью повторяет описанный выше F-тест Фишера для регрессии.\n",
    "\n",
    "$$R^2 = \\frac{SSM}{SSE}$$\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала рассчитаем F-статистику для числовых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "df = load_iris()\n",
    "X, y = df['data'], df['target']\n",
    "\n",
    "from sklearn.feature_selection import f_regression\n",
    "scores, pvalues = f_regression(X,y)\n",
    "\n",
    "for num, (s,p) in enumerate(zip(scores,pvalues)):\n",
    "    print(\"Feature{}: F-test score={}, p-value={}\\n\".format(num,round(s,2),p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут все атрибуты значимы. Попробуем другой датасет, он поменьше => p-value будут больше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_linnerud\n",
    "df = load_linnerud()\n",
    "X, y = df['data'], df['target'][:,0]\n",
    "scores, pvalues = f_regression(X, y)\n",
    "\n",
    "for num, (s,p) in enumerate(zip(scores,pvalues)):\n",
    "    print(\"Feature{}: F-test score={}, p-value={}\\n\".format(num,round(s,2),p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим селектор на базе данной статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFdr, SelectFpr, SelectFwe\n",
    "feature_selector = SelectFpr(score_func=f_regression, alpha=0.05)\n",
    "feature_selector.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем, что он насчитал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_selector.pvalues_)\n",
    "print(feature_selector.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = feature_selector.fit_transform(X,y)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что селектор отфильтровал два признака со слишком большими p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем отфильтровать признаки с помощью chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "df = load_wine()\n",
    "X,y = df['data'], df['target']\n",
    "\n",
    "import pandas\n",
    "pandas.DataFrame(X, columns = df['feature_names']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "feature_selector = SelectKBest(score_func=chi2, k=5)\n",
    "feature_selector.fit(X,y)\n",
    "Xnew = feature_selector.transform(X)\n",
    "\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какие признаки оставил селектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pandas.Series(df['feature_names'])\n",
    "feature_names[feature_selector.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "\n",
    "RFE - поиск оптимального набора предикторов путем последовательного удаления \"плохих\" фичей из перовначального набора. \n",
    "\n",
    "Для оценки качества фичей используется любой классификатор, который возвращает списком величину вклада предкитора в качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Sklearn за это отвечает класс RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные параметры класса RFE:\n",
    "- estimator - классификатор\n",
    "- n_features_to_select - какое число признаков нужно в итоге отобрать\n",
    "- step - сколько признаков убирать из набора на каждом шаге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svc = SVR(kernel=\"linear\")\n",
    "rfe = RFE(estimator=svc, n_features_to_select = 10, step=1)\n",
    "\n",
    "Xnew = rfe.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для определения требуемого кол-ва фичей можно воспользоваться удобным методом RFECV.\n",
    "\n",
    "Метод делает то же самое, что GridSearchCV, но сетка параметров и содержит различные кол-ва признаков [1,2 ... k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные параметры:\n",
    "- estimator - классификатор\n",
    "- cv - параметры кросс-валидации\n",
    "- scoring - метрика для оценки качества признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2), scoring='accuracy')\n",
    "\n",
    "Xnew = rfecv.fit_transform(X, y)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем построить график точности классифкатора в зависимости от числа признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Optimal number of features : 3\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=25, n_informative=3,\n",
    "                           n_redundant=2, n_repeated=0, n_classes=8,\n",
    "                           n_clusters_per_class=1, random_state=0)\n",
    "\n",
    "svc = SVC(kernel=\"linear\")\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2), scoring='accuracy')\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.xlabel(\"Number of features selected\")\n",
    "# plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "# plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какие признаки мы в итоге отобрали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можем проследить, в каком порядке убирались признаки. Индекс 1 соотвествует отобранным в итоге признакам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  1, 12, 19, 15,  6, 17,  1,  2, 21, 23, 11, 16, 10, 13, 22,  8,\n",
       "       14,  1, 20,  7,  9,  3,  4, 18])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многие алгоритмы (в том числе RanfomForest и XGBoost) в процессе обучения модели также рассчитывают Feature Importance по всем предикторам. Эти feature importances также можно использовать для отбора признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Sklearn за это отвечает метод SelectFromModel\n",
    "\n",
    "**Что для этого нужно?**\n",
    "\n",
    "Классификатор должен возвращать либо атрибут coef_, либо атрибут feature_importance_\n",
    "\n",
    "Какие есть классификаторы, удовлетворяющие этому требованию:\n",
    "\n",
    "- ансамбли деревьев\n",
    "    - RandomForestClassifier\n",
    "    - ExtraTreesClassifier\n",
    "    \n",
    "- линейные модели с коэффициентами\n",
    "    - LogisticREgression\n",
    "    - LinearRegression\n",
    "\n",
    "- модели с L1-регуляризацией\n",
    "    - LinearSVC\n",
    "    - Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1-регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зануление некоторых коэффициентов - часть процесса L1-регуляризации в линейных моделях. Следовательно его можно использовать для отбора признаков.\n",
    "\n",
    "Чем больше мы поставили коэффициент регуляризации, тем больше коэффициентов зануляется, и тем меньше ненулевых признаков в модели.\n",
    "\n",
    "Опция prefit=True означает, что модель уже обучена и ещё раз ее запускать не нужно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Load some data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Lets make classifer\n",
    "from sklearn.svm import LinearSVC\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "\n",
    "model = SelectFromModel(estimator = lsvc, prefit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяя метод transform() мы отфильтровываем часть плохих признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = model.transform(X)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес считает важность признаков в процессе обучения.\n",
    "\n",
    "Случайный лес состоит из большого количества решающих деревьев. Все деревья разные, так как при построении дерева признак для очередного разбиения выбирается в определнной степени случайно.\n",
    "\n",
    "Важность признака в RandomForest определяется через то, как часто признак участвует в разбиениях. Чем чаще он используется и чем ближе находится разбиение к корню, тем важнее признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Load some data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Lets make classifer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что алгоритм насчитал в качестве важности признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colnum, colname in enumerate(iris['feature_names']):\n",
    "    print(\"Feature{} importance = {}\".format(colnum, round(rf.feature_importances_[colnum],5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию SelectFromModel выбирает все, что выше медианы (то есть половину признаков)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = model.transform(X)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Порог можно поставить и вручную параметром threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelectFromModel(estimator = rf, prefit=True, threshold = 0.1)\n",
    "Xnew = model.transform(X)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё его удобно определять визуально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Отсортируем по убыванию значиомсти\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Посчитаем стандартное отклонение (ошибку) значимости\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ошибка большая из-за того, что датасет маленький"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем например всё, что выше 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_transformer = SelectFromModel(estimator = rf, threshold = 0.25, prefit=True)\n",
    "Xnew = select_transformer.transform(X)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
