{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA (Latent Dirichlet Allocation)\n",
    "\n",
    "LDA - частный случай подхода pLSA.\n",
    "\n",
    "Название из-за того, что в качестве априорного распределения используется распределение Дирихле.\n",
    "\n",
    "Рассмотрим отдельно несколько тем, которые нужны для понимания метода LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plate Notation\n",
    "\n",
    "Plate Notation - способ схематичного изображения графических веротяностных моделей, которые содержат большое число повторяющихся элементов.\n",
    "\n",
    "Цель: удобство восприятия модели\n",
    "\n",
    "Как читается Plate Notation?\n",
    "- Стрелка - наличие зависимости\n",
    "- Закарашенные круги - наблюдаемые переменные\n",
    "- Пустые - латентные переменные\n",
    "- Прямоугольник с числом N внизу - означает \"повторяется N раз\"\n",
    "\n",
    "Проиллюстрируем на примере pLSA\n",
    "\n",
    "<img src=\"img/plate0.png\" width=300>\n",
    "\n",
    "\n",
    "\n",
    "У нас есть M документов (внешняя плашка) и в каждом таком документе N слов (внутренняя). \n",
    "\n",
    "С каждым словом связана латентная переменная c, обозначающая тематику. Веротяность тематики зависит от документа: P(c|d). \n",
    "\n",
    "А распределение конкретного слова w зависит от выбранной тематики P(w|c).\n",
    "\n",
    "Задача pLSA: найти конкретные распределния P(c|d) и P(w|c).\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirichlet Distribution\n",
    "\n",
    "Распределение Дирихле  - вероятностное распределение k-элементного вектора $x=(x_1,x_2 \\dots x_k)$ при условии $\\sum{x_i}=1$.\n",
    "\n",
    "Множество точек, где $\\sum{x_i}=1$ это <a href=\"https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%BC%D0%BF%D0%BB%D0%B5%D0%BA%D1%81\">симплекс</a>. Таким образом, РД - это распределение вероятности k-элементной комбинации на симплексе.\n",
    "\n",
    "По сути, это веротяностное распределение дискретного распределения :)\n",
    "\n",
    "### Параметры рапсределения\n",
    "\n",
    "У распределения Дирихле есть параметры $\\hat{\\alpha} = (\\alpha_1, \\alpha_2, \\dots \\alpha_k)$, задающие конкретный вид распределения: $\\alpha_i > 0$.\n",
    "\n",
    "Посмотрим, как меняется распределение при разных параметрах. Для наглядности возьмем k=3.\n",
    "\n",
    "|$\\bar{\\alpha}$|распределение|\n",
    "|---|---|\n",
    "|(1,1,1) | равномерное распределение |\n",
    "|(0.2,0.2,0.2) | больше вероятности у краев (когда часть $x_i$ зануляется)|\n",
    "|(7,7,7) | больше распределения у центра |\n",
    "|(5,5,2)| сдвигается к одной из вершин |\n",
    "\n",
    "<img src=\"img/dir1.png\" width=300>\n",
    "\n",
    "А если посэмплриуем из распределения Дирихле, то получится примерно вот так:\n",
    "\n",
    "<img src = \"img/dir2.png\" siwth=250>\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В LDA используется байесовский способ подбора параметров. То есть сначала мы выбраем априорное распределение для параметров, а затем корректируем его наблюдаемыми данными.\n",
    "\n",
    "В качестве априорных распределений для $\\alpha$ и $\\beta$ используются распределения Дирихле. Причем используется симметричное распределение \n",
    "- $\\alpha = \\alpha_1 = \\alpha_2 = \\dots = \\alpha_k$ \n",
    "- $\\beta = \\beta_1 = \\beta_2 = \\dots = \\beta_k$\n",
    "\n",
    "LDA в plate нотации выглядит так: \n",
    "<img src=\"img/lda.png\">\n",
    "\n",
    "Как выглядит генерирующий процесс пошагово?\n",
    "1. Для каждого документа генерируем своё распределение тематик  $\\theta_i \\sim Dir(\\alpha)$\n",
    "2. Для каждой тематики генерирем распределение слов $\\phi_j \\sim Dir(\\beta)$\n",
    "3. Для каждого слова документа выбираем тематику $z_{ij} \\sim Multinomial(\\theta_i)$\n",
    "4. Из этой тематики выбираем конкретное слово $w_{ij} \\sim Multinomial(\\phi_{z_{ij}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executive Summary\n",
    "- LDA - классический подход в моделировании тематик документа\n",
    "- Популярные реализации: *Gensim*\n",
    "- Perplexity - правдоподобие модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Меры качества\n",
    "\n",
    "### Perplexity \n",
    "\n",
    "Perplexity - среднее правдоподобие модели:\n",
    "\n",
    "$$P=\\exp\\bigg[ -\\frac{\\sum{\\log{P(w|\\alpha,\\beta)}}}{\\sum{N_d}}\\bigg] = \\exp^{-E \\big[ \\log P(w|\\alpha, \\beta) \\big]}$$\n",
    "\n",
    "где $w$ - слово, $\\alpha, \\beta$ - наденные параметры модели, $N_d$ - кол-во слов в документе d, всего M документов\n",
    "\n",
    "Arxiv: <a href=\"http://dirichlet.net/pdf/wallach09evaluation.pdf\">Wallach09</a>\n",
    "\n",
    "$P \\in [0, +\\inf)$\n",
    "\n",
    "- Если имеем полную разделимость по тематикам и средняя $P(w|\\alpha,\\beta) = 1$, то $P = 0$\n",
    "- Если всё перемешано и средняя $P(w|\\alpha,\\beta) = 0$, то $P = 1$\n",
    "\n",
    "Разумеется, perplexity уменьшается с ростом числа топиков, но можно использовать для подбора других параметров:\n",
    "<img src=\"img/perplexity1.png\" width = 500>\n",
    "\n",
    "Здесь например приведена сетка из 2 параметров модели LDA: num_topics и learning_decay\n",
    "\n",
    "### Coherence\n",
    "\n",
    "Когерентность тематик - группа метрик, считающих \"целостность\" топика по словам, его сотавляющим.\n",
    "\n",
    "Первые метрики были просто расстоянием до плохих topic-word распределений (junk topics). К плохим тематикам можно отнести  те, в которых:\n",
    "- все слова равноверотяны\n",
    "- распределение слов в тематике совпадает с распределением во всем корпусе текстов\n",
    "- тематика распределена равноверотяно по всем документам\n",
    "\n",
    "Метрики качества топиков можно разделить на\n",
    "- Extrinsic - которые требуют внешнего датасета для расчета\n",
    "- Intrinsic - не требуют\n",
    "\n",
    "Наиболее распространены две метрики: \n",
    "- UMass (intrinsic)\n",
    "- UCI (extrinsic)\n",
    "\n",
    "Обе сначала считаются для каждой пары слов (pairwise), составляющих тематику, а затем суммируются:\n",
    "\n",
    "$$Coherence = \\sum_{i<j}{score(w_i,w_j)}$$\n",
    "\n",
    "Arxiv: <a href=\"http://dirichlet.net/pdf/mimno11optimizing.pdf\">Wallach09</a>\n",
    "\n",
    "UCI - это Pointwise Mutual Information для пары слов w_i и w_j\n",
    "\n",
    "$$UCI = \\log{\\frac{P(w_i,w_j)}{P(w_i) \\cdot P(w_j)}}$$\n",
    "\n",
    "UMass\n",
    "\n",
    "$$UMass = \\log{\\frac{P(w_i,w_j)+1}{P(w_j)}}$$\n",
    "\n",
    "В Gensim для расчета когерентности топика используют более продвинутый подход, основанный на алгоритме описанном в <a href=\"http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf\">WSDM_Topic_Evaluation</a>\n",
    "\n",
    "<img src=\"\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
