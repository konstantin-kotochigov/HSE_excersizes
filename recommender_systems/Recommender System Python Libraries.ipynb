{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Scikit-learn к сожалению нет готовых методов для генерации рекомендаций (считается, что их можно получить базовым функционалом библиотеки). Однако существует несколько популярных библиотек, упрощающих разработку рекомендательных систем. \n",
    "\n",
    "В этом упражнении рассмотрим три такие билиотеки: **lightFM**, **Surprise** и **Implicit**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">LightFM<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установка:\n",
    "- pip install lightfm\n",
    "- conda install -c conda-forge lightfm\n",
    "- через GUI анаконды (проверить, что добавлен channel \"conda-forge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке есть 2 встроенных датасета: \n",
    "- Movielens (оценки фильмов по шкале 1-5)\n",
    "- Stackexchange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем работать с MovieLens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.datasets import fetch_movielens\n",
    "data = fetch_movielens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Названия фильмов\n",
    "titles = data['item_labels']\n",
    "\n",
    "# Оценки фильмов (обучающая выборка)\n",
    "ratings = data['train'].tocsr()\n",
    "\n",
    "# Оценки фильмов (тестовая выборка)\n",
    "ratings_test = data['test'].tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Данные выгружаются в разреженном формате COO, поэтому для удобства можем перевести в формат CSR (для этого есть метод tocsr()).\n",
    "\n",
    "\n",
    "Проставленные оценки пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть два распространенных способа представления разреженных матриц COO и CSR:\n",
    "\n",
    "- COO - три списка:\n",
    "    - ptr (номер эемента col, с которого отсчитывается новая строка)\n",
    "    - col (номера столбцов)\n",
    "    - data (данные)\n",
    "\n",
    "\n",
    "- CSR - три списка:\n",
    "    - row (номера строк)\n",
    "    - col (намера стоблцов)\n",
    "    - data (данные)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание модели сводится к нескольким строкам.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "model = LightFM(loss='warp')\n",
    "model.fit(ratings, epochs=30, num_threads=2)\n",
    "test_precision = precision_at_k(model, ratings_test, k=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем вручную загрузить данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве основного параметра мы передали матрицу оценок. В этом случае выполняется матричная факторизация (matrix factorization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11049842"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Surprise</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая библиотека, которую мы рассмотрим, называется **Surprise**.\n",
    "\n",
    "Варианты усатновки:\n",
    "- pip install scikit-learn\n",
    "- conda -c conda-forge install scikit-surprise\n",
    "- через Anaconda GUI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В бибилиотеке есть 3 тестовых датасета:\n",
    "- MovieLens (100k)\n",
    "- MovieLens (1m)\n",
    "- Jester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгрузим MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the movielens-100k dataset (download it if needed),\n",
    "from surprise import Dataset\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно также загрузить и свой датасет. Для этого создать объект класса Reader с указанием формата файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.expanduser('ml-100k/ratings.data')\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "data = Dataset.load_from_file(file_path, reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доступные в библиотеке Surprise <a href=\"https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html\">алгоритмы</a>:\n",
    "- Baseline, Normal, SlopeOne\n",
    "- kNN\n",
    "- Factorization (SVD, NMF)\n",
    "- CoClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем чуть подробнее несколько алгоритмов из этого списка: Baseline, Slope One и CoClustering\n",
    "\n",
    "**Normal**\n",
    "\n",
    "Прогноз оценки генерируется случайным образом из нормального распределения (чьи параметры оцениваются из данных)\n",
    "\n",
    "**Baseline**\n",
    "\n",
    "Каждая оценка складывается из трех коэффициентов: \n",
    "\n",
    "$\\hat{r}_{ui} = \\mu + b_u + b_i$, где\n",
    "\n",
    "$\\mu$ - глобальный средний рейтинг в системе\n",
    "\n",
    "$b_u$ - насколько данный пользователь ставит оценки выше/ниже, чем среднестатистический юзер\n",
    "\n",
    "$b_i$ - как высоко оценивают данный товар, точнее насколько выше/ниже своей средней оценки\n",
    "\n",
    "Коэффициенты $b_u$ и $b_i$ получаем минимизацией функционала:\n",
    "\n",
    "$\\sum_{r_{ui} \\in R_{train}} \\left(r_{ui} - (\\mu + b_u + b_i)\\right)^2 +\n",
    "\\lambda \\left(b_u^2 + b_i^2 \\right)$\n",
    "\n",
    "Минимизировать можно двумя методами оптимизациями: SGD и ALS.\n",
    "\n",
    "Есть ещё приближенное решение без оптимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SlopeOne**\n",
    "\n",
    "$\\hat{r}_{ui} = \\mu_u + \\frac{1}{\n",
    "|R_i(u)|}\n",
    "\\sum\\limits_{j \\in R_i(u)} \\text{dev}(i, j)$\n",
    "\n",
    "Предположим, пользователь U оценил item1, а мы хотим получить его оценку для item2. \n",
    "Смотрим, насколько в среднем item2 оценивают выше, чем item1 и прибавляем соотвествующую дельту\n",
    "Если пользователь оценил несколько товаров, то считаем такие же дельты для всех оцененных им товаров и получаем средневзвешенную оценку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Co-Clustering**\n",
    "\n",
    "Ключевое предположение - оценка товара зависит во-первых от типа пользователя, во-вторых от типа продукта. \n",
    "\n",
    "То есть, мы выделяем скажем всего 10 типов пользователей и 10 типов продукта, и по каждому такому сочетанию ставим оценку. Процесс выделения подобных блоков в матрице оценок называется bi-clustering или co-clustering.\n",
    "\n",
    "$\\hat{r}_{ui} = \\overline{C_{ui}}$, где $\\overline{C_{ui}}$ - средняя оценка в ко-кластере, в который входят пользователь и товар.\n",
    "\n",
    "Однако у нас есть еще информация по отдельным пользователям и товарам, было бы глупо её не использовать.\n",
    "\n",
    "$\\hat{r}_{ui} = \\overline{C_{ui}} + (\\mu_u - \\overline{C_u}) + (\\mu_i\n",
    "- \\overline{C_i})$, где C_ui - средняя оценка в ко-кластере ui, Cu -  Ci\n",
    "\n",
    "То есть Логика точно та же, что в подходе baseline, но нормировка выполняется отдельно в рамках каждого кластера => прогноз может быть более точным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "algo = SVD()\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделить на Train/Test можно методом train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также в Suprise есть встроенная кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(SVD(), data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также в Suprise есть встроенный GridSearchCV, что сильно упрощает оптимизацию параметров алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'k':[5,10], 'n_epochs': [5, 10], 'lr_all': [0.002, 0.005], 'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data.folds():\n",
    "    print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run 5-fold cross-validation and print results\n",
    "from surprise.model_selection import cross_validate\n",
    "cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Implicit<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implicit** - библиотека, заточенная под работу с неявными рейтингами (когда оценки нету, а проявлением интереса считается просмотр, клик и прочее), отсюда название.\n",
    "\n",
    "Варианты установки:\n",
    "\n",
    "- pip install implicit\n",
    "- conda install -c conda-forge implicit\n",
    "- Anaconda GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "\n",
    "import os\n",
    "import pandas\n",
    "data_path = \"/Users/Konstantin/HSE/MasterProgram/Практический Семинар/Recommender Systems/RecSys_lesson1/ml-1m/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка тестового датасета выполняется методом **get_movielens()**. Параметр variant определяет размер загружаемой выборки. Мы будем использовать \"1m\" (1 млн оценок).\n",
    "\n",
    "На выходе:\n",
    "- ratings - матрица оценок (в sparse-формате)\n",
    "- titles - названия товаров (фильмы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.datasets.movielens import get_movielens\n",
    "titles, ratings = get_movielens(variant='1m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем матрицу оценок к бинарному формату 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "ratings.data[ratings.data < 4.0] = 0\n",
    "ratings.eliminate_zeros()\n",
    "ratings.data = numpy.ones(len(ratings.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3953, 6041)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В implicit есть несколько моделей:\n",
    "- AlternatingLeastSquares\n",
    "- BayesianPersonalizedRanking\n",
    "- TFIDFRecommender\n",
    "- CosineRecommender\n",
    "- BM25Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15.0/15 [00:04<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=50)\n",
    "model.fit(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем какого-нибудь юзера и посмотрим, какие фильмы ему понравились"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars: Episode IV - A New Hope (1977)\n",
      "Jurassic Park (1993)\n",
      "Die Hard (1988)\n",
      "E.T. the Extra-Terrestrial (1982)\n",
      "Raiders of the Lost Ark (1981)\n",
      "Good, The Bad and The Ugly, The (1966)\n",
      "Alien (1979)\n",
      "Terminator, The (1984)\n",
      "Jaws (1975)\n",
      "Rocky (1976)\n",
      "Saving Private Ryan (1998)\n",
      "King Kong (1933)\n",
      "Run Lola Run (Lola rennt) (1998)\n",
      "Goldfinger (1964)\n",
      "Fistful of Dollars, A (1964)\n",
      "Thelma & Louise (1991)\n",
      "Hustler, The (1961)\n",
      "Mad Max (1979)\n"
     ]
    }
   ],
   "source": [
    "userid = 4\n",
    "for y in [titles[x] for x in numpy.nonzero(ratings.T[userid,:])[1]]:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерировать реокемндации - model.recommend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(589, 0.4580247),\n",
       " (2571, 0.4282091),\n",
       " (1291, 0.40621763),\n",
       " (1304, 0.38326198),\n",
       " (1196, 0.37946856)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_film_ids = model.recommend(userid=userid, user_items=ratings.T.tocsr(), N=5)\n",
    "recommended_film_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем айдишники в названия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Terminator 2: Judgment Day (1991)', 0.4580247),\n",
       " ('Matrix, The (1999)', 0.4282091),\n",
       " ('Indiana Jones and the Last Crusade (1989)', 0.40621763),\n",
       " ('Butch Cassidy and the Sundance Kid (1969)', 0.38326198),\n",
       " ('Star Wars: Episode V - The Empire Strikes Back (1980)', 0.37946856)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommened_film_ids = [(titles[x[0]],x[1]) for x in recommended_film_ids]\n",
    "recommened_film_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 1655,  285, ...,   33,   27,  264], dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.ediff1d(ratings.indptr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
