{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном упражнении мы посчитаем рекомендации методом коллаборативной фильтрации Collaborative Filtering.\n",
    "\n",
    "Мы будем использовать классический датасет MovieLens (1m записей), поэтому необходимо загрузить его с сайта GroupLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Повторение теории**\n",
    "\n",
    "В центре любой рекомендательной системы находится матрица оценок (ratings matrix). По строкам в ней идут пользователи (users), по стоблцам - товары (items), пересечение - оценка товара пользователем (ratings). \n",
    "\n",
    "Задача рекомендательной системы:\n",
    "1. спрогнозировать рейтинг товара для тех пар (user, item), где еще не выставлялись оценки\n",
    "2. на основании предсказанной матрицы оценок предложить список товаров для рекомендации пользователю\n",
    "\n",
    "Суть метода: предложить то,что любят клиенты со схожими привычками. Для реокмендации требуется оценить привычки других пользоватлеей системы, отсюда название - \"коллаборативная\".\n",
    "\n",
    "Классическая реализация алгоритма использует принцип k-ближайших соседей (kNN). \n",
    "- По каждому пользователю ищем топ-k наиболее похожих на него\n",
    "- Оценки соседей агрегируем (например, путем расчета взвешенного средних оценок)\n",
    "- Среди тех, которые пользователь еще не оценивал, показываем товары с наилучшим средним ретингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "data_path = \"/Users/Konstantin/HSE/MasterProgram/Практический Семинар/Recommender Systems/RecSys_lesson1/ml-1m/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем пользовательские оценки (файл ratings.dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pandas.read_csv(data_path + \"ratings.dat\", sep=\"::\", names=['user_id','movie_id','rating','ts'])\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем справочник фильмов (movies.dat). Он понадобится дальше для вывода названий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pandas.read_csv(data_path + \"movies.dat\", sep=\"::\", names=['movie_id','title','genre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете имеем 1 млн оценок (достаточно неплохо)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно преобразовать список рейтингов в стандартный матричный формат (user x item => rating). Для этого используем удобный метод pivot()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из справочника фильмов делаем словарь. По идентификаторам будем смортеть названия фильмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2title = dict(zip(movies.index, movies.title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам важно перевести матрицу в сжатое (sparse) представление, иначе при дальнейшем подсчете попарных расстояний рискуем быстро \"съесть\" всю память! (можете поэкспериментировать)\n",
    "\n",
    "Для этого подгружаем из библиотеки scipy нужный нам тип csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "R = csr_matrix(R.values)\n",
    "type(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем посчитать матрицу расстояний, например, с помощью метрики cosine_similarity из библиотеки sklearn, а затем вручную отбирать ближайших пользователей..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = cosine_similarity(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...Но удобнее воспользоваться классом NearestNeighbors из той же библиотеки scikit-learn, который позволяет искать ближашие точки (соседей) по отношению к заданной.\n",
    "\n",
    "Параметры класса\n",
    "- algorithm \n",
    "  - 'brute' - не преобразуем исходную выборку, а при каждом запросе на поиск полностью сканируем ее (brute-force)\n",
    "  - 'kd-tree' или 'ball-tree' - строим специальное дерево для ускорения поиска по выборке, дерево хранится в памяти\n",
    "- metric (какой метрикой мы считаем близость точек)\n",
    "    - 'cosine' - косинусная близость\n",
    "    - кроме того можно выбрать из 25 разных метрик\n",
    "- n_neighbors - количество возвращаемых ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10, n_jobs=-1)\n",
    "model_knn.fit(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание, что посколько мы выбрали алгоритм 'brute', при вызове метода fit() никакие расстояния не рассчитываются, а просто подгружается матрица рейтингов R. Рассчитываться они будут по необходимости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, мы генерируем рекомендации для пользователя user_id = 0 и на его домашней странице хотим показать ему n_neighbors = 10 рекомендаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_user_id=0\n",
    "n_neighbors = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найти ближайших соседей можно методом kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, neighbors = model_knn.kneighbors(R[current_user_id], n_neighbors=n_neighbors+1)\n",
    "neighbors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание, что при использовании метода kneighbors() в списке соседей возвращается и сам пользователь. Расстояние до себя всегда равно 0, поэтому любой пользователь всегда вяляется ближайшим соседом к себе.\n",
    "\n",
    "Если бы мы искали соседей ближайших к произвольно выбранной точке, нам бы такая логика подошла, но поскольку мы ищем соседей конкретного пользователя, давайте список соседей отфильтруем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbors = neighbors[0][1:]\n",
    "distances = distances[0][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сколько рейтингов проставили \"соседи\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.sum(R[neighbors], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ агрегировать рейтинги от нескольких соседей - усреднить их. \n",
    "\n",
    "Ставим правильный axis, ведь нам нужно усреднять по стоблцам (по стоблцам у нас отложены фильмы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "predicted_ratings = numpy.mean(R[neighbors].todense(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А ещё лучше не усреднить, а взвесить по расстояниям (будем давать больший вес тем пользователям, кто ближе). В numpy для этого есть удобная функция average()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_ratings = numpy.average(R[neighbors].todense(), weights=distances, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь отсортируем фильмы в порядке убывания среднего рейтинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toy Story (1995)',\n",
       " 'Brady Bunch Movie, The (1995)',\n",
       " 'Junior (1994)',\n",
       " 'Hour of the Pig, The (1993)',\n",
       " \"I Don't Want to Talk About It (De eso no se habla) (1993)\",\n",
       " 'African Queen, The (1951)',\n",
       " 'Farewell to Arms, A (1932)',\n",
       " 'Unhook the Stars (1996)',\n",
       " 'King of New York (1990)',\n",
       " 'Metropolitan (1990)']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_films_ids = sorted(zip(predicted_ratings, range(len(predicted_ratings))), key = lambda x: -x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем топ-10  рекомендаций и выпишем названия рекомендуемых фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[id2title[x[1]] for x in recommended_films_ids if x[0] > 0.0][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Минусы:**\n",
    "\n",
    "При таком подходе нам нужно считать матрицу расстояний! Попробуйте проделать данное упражнение не с 6000 пользователей, с 1 млн. В итоге получится матрица расстояний с  10^12 элементов, а это примерно 8 терабайт данных. Есть способы как можно частично ускорить, но все они требуют затрат. \n",
    "\n",
    "Если есть требование считать быстро, рекомендуется сделать выбор в пользу матричных разложений. Они используют те же данные (матрицу оценок), но считаются в разы эфективнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полный текст кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load Data\n",
    "data_path = \"/Users/Konstantin/HSE/MasterProgram/Практический Семинар/Recommender Systems/RecSys_lesson1/ml-1m/\"\n",
    "ratings = pandas.read_csv(data_path + \"ratings.dat\", sep=\"::\", names=['user_id','movie_id','rating','ts'])\n",
    "movies = pandas.read_csv(data_path + \"movies.dat\", sep=\"::\", names=['movie_id','title','genre'])\n",
    "\n",
    "# Format Data\n",
    "R = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "id2title = dict(zip(movies.index, movies.title))\n",
    "R = csr_matrix(R.values)\n",
    "\n",
    "# Create Nearest Neghbor Model\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10, n_jobs=-1)\n",
    "model_knn.fit(R)\n",
    "\n",
    "# Get Neighbors \n",
    "current_user_id=0\n",
    "n_neighbors = 10\n",
    "distances, neighbors = model_knn.kneighbors(R[current_user_id], n_neighbors=n_neighbors+1)\n",
    "\n",
    "neighbors = neighbors[0][1:]\n",
    "distances = distances[0][1:]\n",
    "\n",
    "import numpy\n",
    "predicted_ratings = numpy.mean(R[neighbors].todense(), axis=0)\n",
    "\n",
    "recommended_films_ids = sorted(zip(predicted_ratings, range(len(predicted_ratings))), key = lambda x: -x[0])\n",
    "\n",
    "[id2title[x[1]] for x in recommended_films_ids if x[0] > 0.0][0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
