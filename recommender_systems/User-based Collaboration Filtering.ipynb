{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном упражнении мы посчитаем рекомендации методом коллаборативной фильтрации Collaborative Filtering.\n",
    "\n",
    "Мы будем использовать классический датасет MovieLens (1m записей), поэтому необходимо загрузить его с сайта GroupLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Повторение теории**\n",
    "\n",
    "В центре любой рекомендательной системы находится матрица оценок (ratings matrix). По строкам в ней идут пользователи (users), по стоблцам - товары (items), пересечение - оценка товара пользователем (ratings).\n",
    "\n",
    "<img src=img/user_item.png width=350>\n",
    "\n",
    "Задача рекомендательной системы:\n",
    "1. спрогнозировать рейтинг товара для тех пар (user, item), где еще не выставлялись оценки\n",
    "2. на основании предсказанной матрицы оценок предложить список товаров для рекомендаций каждому пользователю\n",
    "\n",
    "Суть метода коллаборативной фильтрации: предложить то,что любят клиенты со схожими привычками. Для реокмендации требуется оценить привычки других пользоватлеей системы, отсюда название - \"коллаборативная\".\n",
    "\n",
    "Классическая реализация алгоритма использует принцип k-ближайших соседей (kNN). \n",
    "- По каждому пользователю ищем топ-k наиболее похожих на него\n",
    "- Оценки соседей агрегируем (например, путем расчета взвешенного средних оценок)\n",
    "- Среди тех, которые пользователь еще не оценивал, показываем товары с наилучшим средним ретингом\n",
    "\n",
    "<img src=img/ub.png width=550>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import numpy\n",
    "data_path = \"/Users/Konstantin/HSE/MasterProgram/Практический Семинар/Recommender Systems/RecSys_lesson1/ml-1m/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем пользовательские оценки (файл ratings.dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Konstantin/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating         ts\n",
       "0        1      1193       5  978300760\n",
       "1        1       661       3  978302109\n",
       "2        1       914       3  978301968\n",
       "3        1      3408       4  978300275\n",
       "4        1      2355       5  978824291"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pandas.read_csv(data_path + \"ratings.dat\", sep=\"::\", names=['user_id','movie_id','rating','ts'])\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем справочник фильмов (movies.dat). Он понадобится дальше для вывода названий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Konstantin/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "movies = pandas.read_csv(data_path + \"movies.dat\", sep=\"::\", names=['movie_id','title','genre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете имеем 1 млн оценок (достаточно неплохо)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000209, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно преобразовать список рейтингов в стандартный матричный формат (user x item => rating). Для этого используем удобный метод pivot()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из справочника фильмов делаем словарь. По идентификаторам будем смортеть названия фильмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2title = dict(zip(movies.index, movies.title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам важно перевести матрицу в сжатое (sparse) представление, иначе при дальнейшем подсчете попарных расстояний рискуем быстро \"съесть\" всю память! (можете поэкспериментировать)\n",
    "\n",
    "Для этого подгружаем из библиотеки scipy нужный нам тип csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "R = csr_matrix(R.values)\n",
    "type(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем посчитать матрицу расстояний, например, с помощью метрики cosine_similarity из библиотеки sklearn, а затем вручную отбирать ближайших пользователей..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = cosine_similarity(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...Но удобнее воспользоваться классом NearestNeighbors из той же библиотеки scikit-learn, который позволяет искать ближашие точки (соседей) по отношению к заданной.\n",
    "\n",
    "Параметры класса\n",
    "- algorithm \n",
    "  - 'brute' - не преобразуем исходную выборку, а при каждом запросе на поиск полностью сканируем ее (brute-force)\n",
    "  - 'kd-tree' или 'ball-tree' - строим специальное дерево для ускорения поиска по выборке, дерево хранится в памяти\n",
    "- metric (какой метрикой мы считаем близость точек)\n",
    "    - 'cosine' - косинусная близость\n",
    "    - кроме того можно выбрать из 25 разных метрик\n",
    "- n_neighbors - количество возвращаемых ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_jobs=-1, n_neighbors=10, p=2, radius=1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10, n_jobs=-1)\n",
    "model_knn.fit(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание, что посколько мы выбрали алгоритм 'brute', при вызове метода fit() никакие расстояния не рассчитываются, а просто подгружается матрица рейтингов R. Рассчитываться они будут по необходимости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, мы генерируем рекомендации для пользователя user_id = 0 и на его домашней странице хотим показать ему n_neighbors = 10 рекомендаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user_id=0\n",
    "n_neighbors = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найти ближайших соседей можно методом kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 5342, 5189, 1480, 1282, 5704, 5761, 1358, 1475,  540, 1857])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances, neighbors = model_knn.kneighbors(R[current_user_id], n_neighbors=n_neighbors+1)\n",
    "neighbors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание, что при использовании метода kneighbors() в списке соседей возвращается и сам пользователь. Расстояние до себя всегда равно 0, поэтому любой пользователь всегда вяляется ближайшим соседом к себе.\n",
    "\n",
    "Если бы мы искали соседей ближайших к произвольно выбранной точке, нам бы такая логика подошла, но поскольку мы ищем соседей конкретного пользователя, давайте список соседей отфильтруем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = neighbors[0][1:]\n",
    "distances = distances[0][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сколько рейтингов проставили \"соседи\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 167.],\n",
       "        [ 169.],\n",
       "        [ 438.],\n",
       "        [ 154.],\n",
       "        [ 640.],\n",
       "        [1132.],\n",
       "        [ 350.],\n",
       "        [ 263.],\n",
       "        [ 606.],\n",
       "        [ 388.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.sum(R[neighbors], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ агрегировать рейтинги от нескольких соседей - усреднить их. \n",
    "\n",
    "Ставим правильный axis, ведь нам нужно усреднять по стоблцам (по стоблцам у нас отложены фильмы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "predicted_ratings = numpy.mean(R[neighbors].todense(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А ещё лучше не усреднить, а взвесить по расстояниям (будем давать больший вес тем пользователям, кто ближе). В numpy для этого есть удобная функция average()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_ratings = numpy.average(R[neighbors].todense(), weights=distances, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь отсортируем фильмы в порядке убывания среднего рейтинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toy Story (1995)',\n",
       " 'Brady Bunch Movie, The (1995)',\n",
       " 'Junior (1994)',\n",
       " 'Hour of the Pig, The (1993)',\n",
       " \"I Don't Want to Talk About It (De eso no se habla) (1993)\",\n",
       " 'African Queen, The (1951)',\n",
       " 'Farewell to Arms, A (1932)',\n",
       " 'Unhook the Stars (1996)',\n",
       " 'King of New York (1990)',\n",
       " 'Metropolitan (1990)']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_films_ids = sorted(zip(predicted_ratings, range(len(predicted_ratings))), key = lambda x: -x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем топ-10  рекомендаций и выпишем названия рекомендуемых фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[id2title[x[1]] for x in recommended_films_ids if x[0] > 0.0][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Минусы:**\n",
    "\n",
    "При таком подходе нам нужно считать матрицу расстояний! Попробуйте проделать данное упражнение не с 6000 пользователей, с 1 млн. В итоге получится матрица расстояний с  10^12 элементов, а это примерно 8 терабайт данных. Есть способы как можно частично ускорить, но все они требуют затрат. \n",
    "\n",
    "Если есть требование считать быстро, рекомендуется сделать выбор в пользу матричных разложений. Они используют те же данные (матрицу оценок), но считаются в разы эфективнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полный текст кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load Data\n",
    "data_path = \"/Users/Konstantin/HSE/MasterProgram/Практический Семинар/Recommender Systems/RecSys_lesson1/ml-1m/\"\n",
    "ratings = pandas.read_csv(data_path + \"ratings.dat\", sep=\"::\", names=['user_id','movie_id','rating','ts'])\n",
    "movies = pandas.read_csv(data_path + \"movies.dat\", sep=\"::\", names=['movie_id','title','genre'])\n",
    "\n",
    "# Format Data\n",
    "R = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "id2title = dict(zip(movies.index, movies.title))\n",
    "R = csr_matrix(R.values)\n",
    "\n",
    "# Create Nearest Neghbor Model\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10, n_jobs=-1)\n",
    "model_knn.fit(R)\n",
    "\n",
    "# Get Neighbors \n",
    "current_user_id=0\n",
    "n_neighbors = 10\n",
    "distances, neighbors = model_knn.kneighbors(R[current_user_id], n_neighbors=n_neighbors+1)\n",
    "\n",
    "neighbors = neighbors[0][1:]\n",
    "distances = distances[0][1:]\n",
    "\n",
    "import numpy\n",
    "predicted_ratings = numpy.mean(R[neighbors].todense(), axis=0)\n",
    "\n",
    "recommended_films_ids = sorted(zip(predicted_ratings, range(len(predicted_ratings))), key = lambda x: -x[0])\n",
    "\n",
    "[id2title[x[1]] for x in recommended_films_ids if x[0] > 0.0][0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
